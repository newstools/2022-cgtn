As the practice of artificial intelligence (AI) technology becomes common in our everyday lives, major powers have started integrating machine learning methods into the process of building their military forces. Yet the range of risks the application of AI may generate has fueled international debate. Singapore's Minister for Defense Ng Eng Hen last year called the military use of AI a "great potential impact for destruction and disruption in our time" at the Singapore Defense Technology Summit held on October 12. Numerous military experts have also addressed the potential threats posed by an increasing integration of AI in military systems. The authors of a 2020 report by the RAND Corporation determined that while AI technology that runs on big data and machine learning would help making decisions faster, international competition could encourage countries to rush the development of military AI without sufficient attention to safety, reliability and humanitarian consequences. The development of AI presents risks ranging across ethical, operational and strategic standpoints, they stated. Operational risks arise from the reliability, fragility and security of AI systems, while strategic risks may entice the likelihood of war, escalate ongoing conflicts and proliferate malicious actors, the report said. Ethical concerns continued to be highlighted for potential mistakes AI technology could make â€“ when facial recognition software labels innocent citizens as criminals or terrorists, for instance. Even with a well-rounded AI system, its ability to make decisions and overwrite human control worries the international community, the report's authors found based on an assessment of several surveys. Military use of AI poses significant risks to international stability for it reshapes the characteristics of future warfare and incites unplanned military actions, said the authors and fellows involved in the Technology and National Security Program at the Center for a New American Security (CNAS) in a report published in 2021. "Recognizing the risks is not enough, however," said the authors of the CNAS report, Michael Horowitz and Paul Scharre. They put forward practical approaches that "explore the potential use of confidence-building measures (CBMs)... in preventing inadvertent war" to ensure a responsible adoption of military AI. Adopting CMB requires "unilateral, bilateral, and/or multilateral actions that states can take to build trust and prevent inadvertent military conflict," they added. In this area, China proposed a position paper on regulating the military applications of artificial intelligence (AI) to the sixth review conference of the United Nations (UN) Convention on Certain Conventional Weapons on December 13, 2021. The paper petitioned for "a vision of common, comprehensive, cooperative and sustainable global security," and to "seek consensus on regulating military applications of AI through dialogue and cooperation, and establish an effective governance regime in order to prevent serious harm or even disasters caused by military applications of AI to mankind." As endorsed by Horowitz and Scharre, establishing confidence-building measures promotes international stability, and exploring ways to shape the dialogue about AI could make the adoption of CBMs more likely. China's position paper showed its determination to promote international security governance, according to Li Song, the Chinese ambassador for disarmament affairs. "Such efforts will help promote mutual trust among countries, safeguard global strategic stability, prevent an arms race and alleviate humanitarian concerns. It will also contribute to building an inclusive and constructive security partnership and striving for the vision of building a community with a shared future for humankind in the AI field," Li said.